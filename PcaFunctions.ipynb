{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import random\n",
    "import sklearn.neighbors as neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X a DxN array, d the dimension of the subspace\n",
    "#Returns mu = 1xD average of the data,\n",
    "# U = Dxd low dimensional basis,\n",
    "# Y = dxN low dimensional coordinates\n",
    "def Pca(X, d):\n",
    "    avg = np.mean(X, axis = 1)\n",
    "    centered = X - avg.reshape(X.shape[0], 1)\n",
    "    U, S, Vt = np.linalg.svd(centered, full_matrices=False)\n",
    "    Y = np.diag(S[0:d]) @ Vt[0:d, :]\n",
    "    return avg, U[:, 0:d], Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the number of dimensions spanning the low dimensional subspace of the data\n",
    "#Parameters: X, DxN data matrix; tau, eigenvalue threshold (as a percentage of total energy)\n",
    "def PcaModelSelection(X, tau):\n",
    "    U, S, Vt = np.linalg.svd(X, full_matrices = False)\n",
    "    tot = 0\n",
    "    for i in S:\n",
    "        tot += i**2\n",
    "    count = 0\n",
    "    while (tot > tau):\n",
    "        tot -= S[count]**2\n",
    "        count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to test dimensional agreements\n",
    "# a = np.random.rand(50, 100)\n",
    "# b = np.zeros((50, 70))\n",
    "# b[0, :] = np.transpose(np.ones(70)) * 50\n",
    "# b = b + np.random.rand(50,70)\n",
    "# c = np.concatenate((a, b), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft thresholding operator\n",
    "#Inputs: x, a float, and tau, the threshold value\n",
    "#Returns: Soft threshold of x\n",
    "def STau(x, tau):\n",
    "    if (x < -tau):\n",
    "        return x + tau\n",
    "    elif (x > tau):\n",
    "        return x - tau\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singular value thresholding of matrix A\n",
    "#Inputs: A, matrix to be thresholded and tau, the threshold value\n",
    "#Returns U*STau(Sigma, tau)*Vt, where U*Sigma*Vt is the SVD of A\n",
    "def DTau(A, tau):\n",
    "    U, S, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "    for i in S:\n",
    "        i = STau(i, tau)\n",
    "    A = U @ np.diag(S) @ Vt\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low rank matrix completion using convex optimization\n",
    "#and Singular Value Thresholding\n",
    "#Inputs: X- The observed data matrix (DxN)\n",
    "#W- matrix of 0's and 1's corresponding to unknown and known entries (DxN)\n",
    "#tau- parameter in potimization problem\n",
    "#beta- step size in dual gradient ascent\n",
    "def LRMC(X, W, tau, beta):\n",
    "    Z0 = np.zeros(X.size())\n",
    "    A = Z0\n",
    "    Z1 = Z0 + beta * (W * (X - A))\n",
    "    threshold = np.norm(Z1, 1) * 0.00001\n",
    "    while (np.norm(Z1-Z0, 1) > threshold):\n",
    "        Z0 = Z1\n",
    "        A = DTau(W * Z1, tau)\n",
    "        Z1 = Z0 + beta * (W * (X - A))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the kernel matrix given data and a specified kernel function\n",
    "#Inputs: X- DxN data matrix, kernel- kernel function\n",
    "#Returns: matrix k where k[i][j] is the kernel function output\n",
    "#with the i-th and j-th data columns supplied as inputs\n",
    "def getKernel(X, kernel):\n",
    "    N = X.shape[1]\n",
    "    k = np.empty([N, N])\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            k[i, j] = kernel(X[:, i], X[:, j])\n",
    "    return k\n",
    "\n",
    "#Returns the local PCA coordinates from a nonlinear embedding\n",
    "#in high dimensional space\n",
    "#Inputs: X- DxN data matrix, kernel-kernel function, d- number of principal components to compute\n",
    "#Returns: Y- dxN local coordinate matrix\n",
    "def Kpca(X, kernel, d):\n",
    "    K = getKernel(X, kernel)\n",
    "    N = X.shape[1]\n",
    "    one_N = np.ones(N)\n",
    "    J = np.identity(N) - (1 / N) * (one_N @ np.transpose(one_N))\n",
    "    k_hat = J @ K @ J\n",
    "    w, v = np.linalg.eig(k_hat)\n",
    "    print(w.shape)\n",
    "    Y = np.diag(np.sqrt(w[0:d])) @ np.transpose(v)[0:d, :]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolynomialKernel(x, y):\n",
    "    return np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrix completion by direct power factorization. More efficient than LRMC\n",
    "#calculating SVD at every iteration.\n",
    "#Inputs: X- DxN data matrix with missing entries, d- the number of principal components to use\n",
    "#Outputs: Completion of X\n",
    "def MCByPower(X, d):\n",
    "    Y0 = np.random.rand(d, X.shape[1])\n",
    "    Y_next = Y0\n",
    "    Y = np.zeros(Y_next.shape) \n",
    "    U_next = X @ Y0 @ np.linalg.inv(Y0 @ np.transpose(Y0))\n",
    "    Q, R = np.linalg.qr(U_next)\n",
    "    U_next = Q\n",
    "    U = np.zeros(U_next.shape)\n",
    "    threshold = np.norm(U_next @ Y_next) * 0.001\n",
    "    while (np.linalg.norm(U_next @ Y_next) - np.norm(U @ Y) > threshold):\n",
    "        Y = Y_next\n",
    "        Y_next = np.transpose(U) @ X\n",
    "        U = U_next\n",
    "        U_next = X @ X @ Y_next @ np.linalg.inv(Y_next @ np.transpose(Y_next))\n",
    "        Q, R = np.linalg.qr(U_next)\n",
    "        U_next = Q\n",
    "    return U_next @ Y_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of k-means algorithm\n",
    "#Inputs: X- DxN data matrix, d- number of groups\n",
    "#Returns: Dxn- matrix where the i-th column is the i-th centroid\n",
    "#W- nxN membership matrix W where W[i, j] = 1 iff X_j is a member of gorup i\n",
    "def KMeans(X, n):\n",
    "    N = X.shape[1]\n",
    "\n",
    "    start_indices = random.sample(range(0, N), n)\n",
    "    centers = X[:, start_indices]\n",
    "    w1 = np.zeros((n, N))\n",
    "    w0 = np.ones((n, N))\n",
    "    count = 0\n",
    "    while (np.linalg.norm(w1 - w0, 'nuc') > 0):\n",
    "        w0 = w1\n",
    "        w1 = np.zeros((n, N))\n",
    "        dist = cdist(np.transpose(X), np.transpose(centers), 'euclidean')\n",
    "        groups = np.argmin(dist, axis=1)\n",
    "        print(groups)\n",
    "        count += 1\n",
    "        w1[groups, range(N)] = 1\n",
    "        centers = X @ (w1.T / np.sum(w1, axis = 1))\n",
    "    return centers, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[50.43136763,  0.49555876],\n",
       "        [ 0.47141483,  0.54761687],\n",
       "        [ 0.48160644,  0.48673812],\n",
       "        [ 0.52366881,  0.52917423],\n",
       "        [ 0.45799294,  0.55437026],\n",
       "        [ 0.55243638,  0.54765783],\n",
       "        [ 0.50688354,  0.51519311],\n",
       "        [ 0.46756168,  0.48262751],\n",
       "        [ 0.50002283,  0.52491398],\n",
       "        [ 0.53905569,  0.49179028],\n",
       "        [ 0.42949098,  0.47727026],\n",
       "        [ 0.49119132,  0.49720717],\n",
       "        [ 0.55940495,  0.53157426],\n",
       "        [ 0.51658544,  0.51775062],\n",
       "        [ 0.47931969,  0.51087333],\n",
       "        [ 0.51908833,  0.50813499],\n",
       "        [ 0.49862152,  0.50153215],\n",
       "        [ 0.462986  ,  0.48858178],\n",
       "        [ 0.57388241,  0.49311133],\n",
       "        [ 0.49487335,  0.47998455],\n",
       "        [ 0.51833069,  0.4698341 ],\n",
       "        [ 0.56402453,  0.49095644],\n",
       "        [ 0.4659353 ,  0.472994  ],\n",
       "        [ 0.47890512,  0.48843033],\n",
       "        [ 0.50074262,  0.5049674 ],\n",
       "        [ 0.50841531,  0.52651755],\n",
       "        [ 0.46705961,  0.50494076],\n",
       "        [ 0.56158523,  0.44845843],\n",
       "        [ 0.48470832,  0.45520771],\n",
       "        [ 0.45179069,  0.52748422],\n",
       "        [ 0.51486268,  0.43582894],\n",
       "        [ 0.49184358,  0.51696612],\n",
       "        [ 0.52937116,  0.4865525 ],\n",
       "        [ 0.50949118,  0.48767814],\n",
       "        [ 0.48421298,  0.5470359 ],\n",
       "        [ 0.52231647,  0.50223225],\n",
       "        [ 0.53510905,  0.48332978],\n",
       "        [ 0.4869767 ,  0.49092376],\n",
       "        [ 0.48081253,  0.47386147],\n",
       "        [ 0.55437414,  0.51936858],\n",
       "        [ 0.48861813,  0.46556048],\n",
       "        [ 0.47929477,  0.47774923],\n",
       "        [ 0.54822213,  0.51718439],\n",
       "        [ 0.54358677,  0.49925038],\n",
       "        [ 0.44618572,  0.54611812],\n",
       "        [ 0.54458696,  0.56042258],\n",
       "        [ 0.5105759 ,  0.51268491],\n",
       "        [ 0.46996234,  0.50959316],\n",
       "        [ 0.54553375,  0.51310925],\n",
       "        [ 0.55077247,  0.52477095]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Implementation of spectral clustering algorithm\n",
    "#Inputs: n- number of groups, W- a NxN affinity matrix\n",
    "#Returns: nxN membership matrix where W[i, j] = 1 iff X_j is a\n",
    "#member of gorup i, computed by k-means\n",
    "def SpectralCluster(n, W):\n",
    "    N = W.shape[0]\n",
    "    D = np.diag(W @ np.ones(N))\n",
    "    L = D - W\n",
    "    w, v = np.linalg.eig(L)\n",
    "    Y = w[:, -n].T\n",
    "    centers, groups = KMeans(Y, n)\n",
    "    return groupsvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNNByRadius(X, epsilon):\n",
    "    tree = neighbors.BallTree(X.T)\n",
    "    ind = tree.query_radius(X.T[:], r = epsilon)\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNNByNumber(X, K):\n",
    "    tree = neighbors.BallTree(X.T)\n",
    "    dist, ind = tree.query(X[:], k = K)\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STauMatrix(X, tau):\n",
    "    A = np.zeros(X.shape)\n",
    "    for idx, x in np.ndenumerate(X):\n",
    "        A[idx] = STau(x, tau)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a sparse local representation C so that X = XC by minimizing L1 norm and \n",
    "#augmenting reconstruction error\n",
    "#Inputs: X- DxN data Matrix, tau- reconstruction error parameter (higher means that the matrix\n",
    "# will be more exact at the expense of sparsity), mu- second optimization parameter of the \n",
    "#augmented Lagrangian\n",
    "#Returns: sparse representation C s.t. X is approx. XC\n",
    "def LASSOMinimizationADMM(X, tau, mu):\n",
    "    D, N = X.shape\n",
    "    C0 = np.zeros([N, N])\n",
    "    L0 = np.zeros([N, N])\n",
    "    Z1 = np.linalg.inv(tau * X.T @ X + mu * np.identity(N)) * (tau * X.T @ X)\n",
    "    C1 = STauMatrix(Z1, 1 / mu).fill_diagonal(0)\n",
    "    L1 = mu * (Z1 - C1)\n",
    "    threshold = 0.0001 * np.linalg.norm(C1, 1)\n",
    "    while (np.linalg.norm(C1 - C0, 1) > threshold):\n",
    "        C0 = C1\n",
    "        L0 = L1\n",
    "        Z0 = Z1\n",
    "        Z1 = np.linalg.inv(tau * X.T @ X + mu * np.identity(N)) * \\\n",
    "            (tau * X.T @ X + mu * (C0 - L0 / mu))\n",
    "        C1 = STauMatrix(Z1 + L0 / mu, 1 / mu).fill_diagonal(0)\n",
    "        L1 = L0 + mu * (Z1 - C1)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computes clustering of data into subspaces with the sparse subspace clustering\n",
    "#algorithm augmented to handle noisy data.\n",
    "#Inputs: X- DxN data matrix, n- number of subspaces, tau- Optimization parameter\n",
    "#Increasing tau will prioritize an accurate reconstruction at the risk that the\n",
    "#underlying representation is not sparse, leading to \n",
    "#subspace mixing. Tau too low will not give an accurate\n",
    "#reconstruction of the data and therefore clustering cannot be trusted.\n",
    "#Returns: nxN membership matrix W where W[i, j] = 1 iff X_j is a\n",
    "#member of gorup i\n",
    "def SSCWithNoise(X, n, tau):\n",
    "    C = LASSOMinimizationADMM(X, tau, tau)\n",
    "    W = C + C.T\n",
    "    return SpectralCluster(n, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performs the local subspace affinity algorithm using euclidean distance\n",
    "#Inputs: X- DxN data matrix, K- number of nearest neighbors to query (should \n",
    "#select K to be sure it's higher than the dimensions of the subspaces), n-\n",
    "#number of subspaces to cluster\n",
    "#Returns: nxN membership matrix W where W[i, j] = 1 iff X_j is a\n",
    "#member of gorup i\n",
    "def LSA(X, K, n):\n",
    "    N, D = X.shape\n",
    "    ind = GetNNByNumber(X, K)\n",
    "    subspaces = {}\n",
    "    for i in range(N):\n",
    "        NN = X[:, ind[i]]\n",
    "        d = PcaModelSelection(NN, 0.99)\n",
    "        mu, U, Y = Pca(NN, d)\n",
    "        subspaces[i] = [U, d]\n",
    "    W = np.zeros([N, N])\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            U, S, Vt = np.linalg.svd(subspaces[i][0].T @ subspaces[j][0])\n",
    "            w = np.square(S[0:np.minimum(subspaces[i][1], \\\n",
    "                                               subspaces[j][1])]).sum\n",
    "            W[i, j] = w\n",
    "            W[j, i] = w\n",
    "    return SpectralCluster(W, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
